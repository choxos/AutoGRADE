# Generated by Django 4.2.8 on 2025-08-16 12:42

from django.conf import settings
import django.core.validators
from django.db import migrations, models
import django.db.models.deletion


class Migration(migrations.Migration):

    dependencies = [
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
        ("grade", "0002_gradeproject_protocol_url_and_more"),
    ]

    operations = [
        migrations.CreateModel(
            name="EnhancedSummaryOfFindings",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("title", models.CharField(max_length=500)),
                ("description", models.TextField(blank=True)),
                (
                    "risk_groups_used",
                    models.BooleanField(
                        default=False,
                        help_text="Does this SoF table stratify by different risk groups?",
                    ),
                ),
                (
                    "baseline_risk_source",
                    models.TextField(
                        blank=True,
                        help_text="Source of baseline risk estimates (systematic review, pragmatic trial, etc.)",
                    ),
                ),
                ("plain_language_included", models.BooleanField(default=True)),
                ("generated_at", models.DateTimeField(auto_now_add=True)),
                (
                    "generated_by",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.CASCADE,
                        to=settings.AUTH_USER_MODEL,
                    ),
                ),
                (
                    "project",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="enhanced_sof_tables",
                        to="grade.gradeproject",
                    ),
                ),
            ],
        ),
        migrations.CreateModel(
            name="InconsistencyAssessment",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                (
                    "forest_plot_file",
                    models.FileField(
                        blank=True,
                        help_text="Upload forest plot image or data file",
                        null=True,
                        upload_to="forest_plots/",
                    ),
                ),
                (
                    "i_squared",
                    models.FloatField(
                        blank=True,
                        help_text="IÂ² statistic (0-100%)",
                        null=True,
                        validators=[
                            django.core.validators.MinValueValidator(0.0),
                            django.core.validators.MaxValueValidator(100.0),
                        ],
                    ),
                ),
                ("i_squared_interpretation", models.TextField(blank=True)),
                (
                    "point_estimates_similar",
                    models.BooleanField(
                        help_text="Are point estimates similar across studies?"
                    ),
                ),
                (
                    "cis_overlap",
                    models.BooleanField(help_text="Do confidence intervals overlap?"),
                ),
                (
                    "effects_same_side_threshold",
                    models.BooleanField(
                        help_text="Are effects on same side of threshold?"
                    ),
                ),
                (
                    "subgroup_hypotheses",
                    models.TextField(
                        blank=True,
                        help_text="A priori subgroup hypotheses to explain heterogeneity",
                    ),
                ),
                ("subgroups_analyzed", models.BooleanField(default=False)),
                (
                    "inconsistency_decision",
                    models.CharField(
                        choices=[
                            ("no_rating_down", "No Rating Down"),
                            ("rate_down_once", "Rate Down Once"),
                            ("rate_down_twice", "Rate Down Twice"),
                        ],
                        max_length=20,
                    ),
                ),
                (
                    "rationale",
                    models.TextField(help_text="Rationale for inconsistency rating"),
                ),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("updated_at", models.DateTimeField(auto_now=True)),
                (
                    "outcome",
                    models.OneToOneField(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="inconsistency_assessment",
                        to="grade.outcome",
                    ),
                ),
            ],
        ),
        migrations.CreateModel(
            name="ValuesAndPreferences",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                (
                    "systematic_review_conducted",
                    models.BooleanField(
                        default=False,
                        help_text="Was a systematic review of values and preferences conducted?",
                    ),
                ),
                (
                    "focus_groups_conducted",
                    models.BooleanField(
                        default=False,
                        help_text="Were focus groups with patients conducted?",
                    ),
                ),
                (
                    "clinical_experience_consulted",
                    models.BooleanField(
                        default=False,
                        help_text="Was clinical experience with shared decision making consulted?",
                    ),
                ),
                (
                    "values_preferences_summary",
                    models.TextField(
                        help_text="Summary of patient values and preferences assessment"
                    ),
                ),
                (
                    "variability_assessment",
                    models.CharField(
                        choices=[
                            ("low", "Low Variability"),
                            ("moderate", "Moderate Variability"),
                            ("high", "High Variability"),
                        ],
                        help_text="Variability in values and preferences across patients",
                        max_length=20,
                    ),
                ),
                (
                    "certainty_in_assessment",
                    models.CharField(
                        choices=[
                            ("high", "High Certainty"),
                            ("moderate", "Moderate Certainty"),
                            ("low", "Low Certainty"),
                        ],
                        help_text="Certainty in values and preferences assessment",
                        max_length=20,
                    ),
                ),
                (
                    "supporting_evidence",
                    models.TextField(
                        blank=True,
                        help_text="Detailed description of supporting evidence",
                    ),
                ),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("updated_at", models.DateTimeField(auto_now=True)),
                (
                    "project",
                    models.OneToOneField(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="values_preferences",
                        to="grade.gradeproject",
                    ),
                ),
            ],
        ),
        migrations.CreateModel(
            name="SubgroupAnalysis",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("subgroup_name", models.CharField(max_length=200)),
                ("subgroup_description", models.TextField()),
                (
                    "hypothesis_prespecified",
                    models.BooleanField(
                        help_text="Was this hypothesis specified a priori?"
                    ),
                ),
                (
                    "within_study_comparison",
                    models.BooleanField(
                        help_text="Is the comparison within studies rather than between studies?"
                    ),
                ),
                (
                    "interaction_test_p_value",
                    models.FloatField(
                        blank=True, help_text="P-value for interaction test", null=True
                    ),
                ),
                (
                    "direction_consistent",
                    models.BooleanField(
                        help_text="Is direction of effect consistent across subgroups?"
                    ),
                ),
                (
                    "biological_plausibility",
                    models.BooleanField(
                        help_text="Is there biological plausibility for the subgroup effect?"
                    ),
                ),
                (
                    "credibility_level",
                    models.CharField(
                        choices=[
                            ("low", "Low Credibility"),
                            ("moderate", "Moderate Credibility"),
                            ("high", "High Credibility"),
                        ],
                        max_length=20,
                    ),
                ),
                ("credibility_rationale", models.TextField()),
                ("subgroup_effect_estimate", models.FloatField(blank=True, null=True)),
                ("subgroup_ci_lower", models.FloatField(blank=True, null=True)),
                ("subgroup_ci_upper", models.FloatField(blank=True, null=True)),
                (
                    "requires_separate_assessment",
                    models.BooleanField(
                        default=False,
                        help_text="Does this subgroup require separate evidence summary and certainty rating?",
                    ),
                ),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("updated_at", models.DateTimeField(auto_now=True)),
                (
                    "inconsistency_assessment",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="subgroup_analyses",
                        to="grade.inconsistencyassessment",
                    ),
                ),
            ],
        ),
        migrations.CreateModel(
            name="RiskGroup",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                (
                    "group_name",
                    models.CharField(
                        help_text="e.g., 'Very low risk', 'High risk'", max_length=200
                    ),
                ),
                (
                    "group_description",
                    models.TextField(
                        help_text="Description of risk group characteristics"
                    ),
                ),
                (
                    "baseline_risk",
                    models.FloatField(
                        help_text="Baseline risk for this group (0.0 to 1.0)"
                    ),
                ),
                (
                    "risk_factors",
                    models.TextField(
                        blank=True, help_text="Risk factors that define this group"
                    ),
                ),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                (
                    "sof_table",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="risk_groups",
                        to="grade.enhancedsummaryoffindings",
                    ),
                ),
            ],
            options={
                "ordering": ["baseline_risk"],
            },
        ),
        migrations.CreateModel(
            name="PublicationBiasAssessment",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                (
                    "funnel_plot_file",
                    models.FileField(
                        blank=True,
                        help_text="Upload funnel plot image",
                        null=True,
                        upload_to="funnel_plots/",
                    ),
                ),
                (
                    "funnel_plot_asymmetric",
                    models.BooleanField(
                        help_text="Is the funnel plot visually asymmetric?"
                    ),
                ),
                (
                    "missing_studies_suspected",
                    models.BooleanField(
                        help_text="Are studies missing from expected regions of funnel plot?"
                    ),
                ),
                ("eggers_test_performed", models.BooleanField(default=False)),
                ("eggers_test_p_value", models.FloatField(blank=True, null=True)),
                ("beggs_test_performed", models.BooleanField(default=False)),
                ("beggs_test_p_value", models.FloatField(blank=True, null=True)),
                ("statistical_test_interpretation", models.TextField(blank=True)),
                (
                    "number_of_studies",
                    models.IntegerField(help_text="Number of studies in meta-analysis"),
                ),
                (
                    "studies_mostly_small",
                    models.BooleanField(help_text="Are most studies small?"),
                ),
                (
                    "industry_sponsorship_common",
                    models.BooleanField(
                        help_text="Are most/all studies industry sponsored?"
                    ),
                ),
                (
                    "unpublished_studies_known",
                    models.BooleanField(
                        default=False, help_text="Are there known unpublished studies?"
                    ),
                ),
                (
                    "unpublished_studies_description",
                    models.TextField(
                        blank=True,
                        help_text="Describe known unpublished studies and their potential impact",
                    ),
                ),
                (
                    "comprehensive_search_performed",
                    models.BooleanField(
                        help_text="Was a comprehensive search performed (multiple databases, registries, etc.)?"
                    ),
                ),
                (
                    "search_strategy_description",
                    models.TextField(
                        blank=True, help_text="Describe search strategy and sources"
                    ),
                ),
                (
                    "publication_bias_decision",
                    models.CharField(
                        choices=[
                            ("undetected", "Publication bias undetected"),
                            (
                                "strongly_suspected",
                                "Publication bias strongly suspected",
                            ),
                        ],
                        max_length=30,
                    ),
                ),
                (
                    "rationale",
                    models.TextField(
                        help_text="Rationale for publication bias assessment"
                    ),
                ),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("updated_at", models.DateTimeField(auto_now=True)),
                (
                    "outcome",
                    models.OneToOneField(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="publication_bias_assessment",
                        to="grade.outcome",
                    ),
                ),
            ],
        ),
        migrations.CreateModel(
            name="MinimalImportantDifference",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("mid_value", models.FloatField(help_text="MID threshold value")),
                (
                    "mid_source",
                    models.CharField(
                        choices=[
                            ("systematic_review", "Systematic Review of MID Studies"),
                            ("anchor_based", "Anchor-based Methods"),
                            ("distribution_based", "Distribution-based Methods"),
                            ("panel_survey", "Panel Survey"),
                            ("focus_group", "Focus Group"),
                            ("clinical_experience", "Clinical Experience"),
                            ("literature_estimate", "Literature Estimate"),
                        ],
                        max_length=30,
                    ),
                ),
                (
                    "supporting_evidence",
                    models.TextField(
                        help_text="Description of evidence supporting this MID value"
                    ),
                ),
                (
                    "confidence_in_mid",
                    models.CharField(
                        choices=[
                            ("high", "High Confidence"),
                            ("moderate", "Moderate Confidence"),
                            ("low", "Low Confidence"),
                        ],
                        max_length=20,
                    ),
                ),
                (
                    "panel_survey_data",
                    models.JSONField(
                        blank=True,
                        help_text="Raw data from panel MID survey",
                        null=True,
                    ),
                ),
                (
                    "alternative_mid_values",
                    models.JSONField(
                        default=list, help_text="Other MID estimates considered"
                    ),
                ),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("updated_at", models.DateTimeField(auto_now=True)),
                (
                    "outcome",
                    models.OneToOneField(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="mid_specification",
                        to="grade.outcome",
                    ),
                ),
            ],
        ),
        migrations.CreateModel(
            name="IndirectnessAssessment",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                (
                    "target_population",
                    models.TextField(help_text="Target population of interest"),
                ),
                (
                    "target_intervention",
                    models.TextField(help_text="Target intervention of interest"),
                ),
                (
                    "target_comparison",
                    models.TextField(help_text="Target comparator of interest"),
                ),
                (
                    "target_outcome",
                    models.TextField(help_text="Target outcome of interest"),
                ),
                ("population_mismatch", models.BooleanField(default=False)),
                (
                    "population_differences",
                    models.TextField(
                        blank=True,
                        help_text="Describe differences between target and study populations",
                    ),
                ),
                ("intervention_mismatch", models.BooleanField(default=False)),
                (
                    "intervention_differences",
                    models.TextField(
                        blank=True,
                        help_text="Describe differences in intervention (dose, duration, adherence, etc.)",
                    ),
                ),
                ("comparator_mismatch", models.BooleanField(default=False)),
                (
                    "comparator_differences",
                    models.TextField(
                        blank=True,
                        help_text="Describe differences in comparator (suboptimal care, placebo vs active, etc.)",
                    ),
                ),
                ("outcome_mismatch", models.BooleanField(default=False)),
                (
                    "outcome_differences",
                    models.TextField(
                        blank=True,
                        help_text="Describe differences in outcome (surrogate vs patient-important, timing)",
                    ),
                ),
                ("is_surrogate_outcome", models.BooleanField(default=False)),
                (
                    "surrogate_relationship_strength",
                    models.CharField(
                        blank=True,
                        choices=[
                            (
                                "strong",
                                "Strong relationship to patient-important outcome",
                            ),
                            ("moderate", "Moderate relationship"),
                            ("weak", "Weak relationship"),
                            ("uncertain", "Uncertain relationship"),
                        ],
                        max_length=20,
                    ),
                ),
                (
                    "indirectness_decision",
                    models.CharField(
                        choices=[
                            ("no_rating_down", "No Rating Down"),
                            ("rate_down_once", "Rate Down Once"),
                            ("rate_down_twice", "Rate Down Twice"),
                        ],
                        max_length=20,
                    ),
                ),
                (
                    "rationale",
                    models.TextField(help_text="Rationale for indirectness rating"),
                ),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("updated_at", models.DateTimeField(auto_now=True)),
                (
                    "outcome",
                    models.OneToOneField(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="indirectness_assessment",
                        to="grade.outcome",
                    ),
                ),
            ],
        ),
        migrations.CreateModel(
            name="ImprecisionAssessment",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                (
                    "threshold_type",
                    models.CharField(
                        choices=[
                            ("mid", "Minimal Important Difference (MID)"),
                            ("null", "Null Effect"),
                        ],
                        max_length=10,
                    ),
                ),
                (
                    "mid_value",
                    models.FloatField(
                        blank=True, help_text="MID threshold value", null=True
                    ),
                ),
                (
                    "null_value",
                    models.FloatField(
                        default=0.0, help_text="Null effect threshold (usually 0 or 1)"
                    ),
                ),
                (
                    "point_estimate",
                    models.FloatField(help_text="Point estimate of effect"),
                ),
                ("ci_lower_bound", models.FloatField(help_text="95% CI lower bound")),
                ("ci_upper_bound", models.FloatField(help_text="95% CI upper bound")),
                (
                    "ci_crosses_threshold",
                    models.BooleanField(help_text="Does CI cross the threshold?"),
                ),
                ("ci_includes_important_benefit", models.BooleanField(default=False)),
                ("ci_includes_important_harm", models.BooleanField(default=False)),
                ("ci_includes_no_effect", models.BooleanField(default=False)),
                ("sample_size", models.IntegerField(blank=True, null=True)),
                (
                    "optimal_information_size",
                    models.IntegerField(blank=True, null=True),
                ),
                ("ois_criterion_met", models.BooleanField(default=False)),
                (
                    "imprecision_decision",
                    models.CharField(
                        choices=[
                            ("no_rating_down", "No Rating Down"),
                            ("rate_down_once", "Rate Down Once"),
                            ("rate_down_twice", "Rate Down Twice"),
                        ],
                        max_length=20,
                    ),
                ),
                (
                    "rationale",
                    models.TextField(help_text="Rationale for imprecision rating"),
                ),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("updated_at", models.DateTimeField(auto_now=True)),
                (
                    "outcome",
                    models.OneToOneField(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="imprecision_assessment",
                        to="grade.outcome",
                    ),
                ),
            ],
        ),
        migrations.CreateModel(
            name="EvidenceToDecisionFramework",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                (
                    "perspective",
                    models.CharField(
                        choices=[
                            ("individual", "Individual Patient Perspective"),
                            (
                                "individual_population",
                                "Individual Patient + Population Perspective",
                            ),
                            ("population", "Population Perspective"),
                        ],
                        max_length=30,
                    ),
                ),
                (
                    "benefits_harms_assessment",
                    models.TextField(
                        help_text="Assessment of balance between benefits, harms, and burdens"
                    ),
                ),
                (
                    "certainty_of_evidence_summary",
                    models.TextField(
                        help_text="Summary of certainty across critical and important outcomes"
                    ),
                ),
                (
                    "values_preferences_statement",
                    models.TextField(
                        help_text="Statement about patients' values and preferences"
                    ),
                ),
                (
                    "resource_costs_assessment",
                    models.TextField(
                        blank=True,
                        help_text="Assessment of costs, savings, and cost-effectiveness",
                    ),
                ),
                (
                    "feasibility_assessment",
                    models.TextField(
                        blank=True, help_text="Assessment of implementation feasibility"
                    ),
                ),
                (
                    "acceptability_assessment",
                    models.TextField(
                        blank=True,
                        help_text="Assessment of acceptability to stakeholders",
                    ),
                ),
                (
                    "equity_assessment",
                    models.TextField(
                        blank=True, help_text="Assessment of impact on health equity"
                    ),
                ),
                (
                    "recommendation_direction_strength",
                    models.CharField(
                        choices=[
                            ("strong_for", "Strong Recommendation For"),
                            ("conditional_for", "Conditional Recommendation For"),
                            (
                                "conditional_against",
                                "Conditional Recommendation Against",
                            ),
                            ("strong_against", "Strong Recommendation Against"),
                            ("either_option", "Either Option Acceptable"),
                            ("research_only", "Only in Research Setting"),
                        ],
                        max_length=30,
                    ),
                ),
                (
                    "recommendation_text",
                    models.TextField(help_text="Full recommendation statement"),
                ),
                (
                    "justification",
                    models.TextField(help_text="Justification for the recommendation"),
                ),
                (
                    "panel_members",
                    models.TextField(
                        blank=True,
                        help_text="List of panel members involved in recommendation",
                    ),
                ),
                ("developed_at", models.DateTimeField(auto_now_add=True)),
                ("updated_at", models.DateTimeField(auto_now=True)),
                (
                    "developed_by",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.CASCADE,
                        to=settings.AUTH_USER_MODEL,
                    ),
                ),
                (
                    "project",
                    models.OneToOneField(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="etd_framework",
                        to="grade.gradeproject",
                    ),
                ),
            ],
        ),
        migrations.CreateModel(
            name="ContinuousOutcomePresentation",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                (
                    "presentation_type",
                    models.CharField(
                        choices=[
                            ("mean_difference", "Mean Difference (Index Instrument)"),
                            ("binary_mid", "Binary (Proportion Above MID)"),
                            (
                                "standardized_mean_difference",
                                "Standardized Mean Difference",
                            ),
                            ("ratio_of_means", "Ratio of Means"),
                        ],
                        max_length=50,
                    ),
                ),
                ("index_instrument_name", models.CharField(blank=True, max_length=200)),
                (
                    "index_instrument_range",
                    models.CharField(
                        blank=True,
                        help_text="e.g., '0-100, higher scores better'",
                        max_length=100,
                    ),
                ),
                ("control_group_value", models.FloatField(blank=True, null=True)),
                ("intervention_group_value", models.FloatField(blank=True, null=True)),
                (
                    "effect_estimate",
                    models.FloatField(help_text="Effect estimate in this format"),
                ),
                ("ci_lower", models.FloatField(help_text="95% CI lower bound")),
                ("ci_upper", models.FloatField(help_text="95% CI upper bound")),
                (
                    "proportion_control",
                    models.FloatField(
                        blank=True,
                        help_text="Proportion achieving MID in control group",
                        null=True,
                    ),
                ),
                (
                    "proportion_intervention",
                    models.FloatField(
                        blank=True,
                        help_text="Proportion achieving MID in intervention group",
                        null=True,
                    ),
                ),
                (
                    "interpretation_notes",
                    models.TextField(
                        blank=True,
                        help_text="Notes on interpreting this presentation format",
                    ),
                ),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                (
                    "outcome",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="presentations",
                        to="grade.outcome",
                    ),
                ),
            ],
        ),
        migrations.CreateModel(
            name="RiskOfBiasAssessment",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                (
                    "tool_used",
                    models.CharField(
                        choices=[
                            ("rob2", "RoB 2 (Cochrane)"),
                            ("robust_rct", "ROBUST-RCT"),
                            ("robins_i", "ROBINS-I"),
                            ("newcastle_ottawa", "Newcastle-Ottawa Scale"),
                            ("clarity_cohort", "CLARITY (Cohort)"),
                            ("clarity_case_control", "CLARITY (Case-Control)"),
                            ("custom", "Custom Tool"),
                        ],
                        max_length=50,
                    ),
                ),
                (
                    "overall_classification",
                    models.CharField(
                        choices=[
                            ("low", "Low Risk of Bias"),
                            ("high", "High Risk of Bias"),
                            ("unclear", "Unclear Risk of Bias"),
                        ],
                        max_length=20,
                    ),
                ),
                (
                    "weight_in_analysis",
                    models.FloatField(
                        blank=True,
                        help_text="Statistical weight of this study in the meta-analysis (0.0 to 1.0)",
                        null=True,
                        validators=[
                            django.core.validators.MinValueValidator(0.0),
                            django.core.validators.MaxValueValidator(1.0),
                        ],
                    ),
                ),
                (
                    "domain_assessments",
                    models.JSONField(
                        default=dict,
                        help_text="Individual domain assessments (e.g., randomization, blinding, etc.)",
                    ),
                ),
                ("assessment_rationale", models.TextField(blank=True)),
                ("reviewer_notes", models.TextField(blank=True)),
                (
                    "rob_data_file",
                    models.FileField(
                        blank=True,
                        help_text="Upload CSV file with RoB assessment data",
                        null=True,
                        upload_to="rob_data/",
                    ),
                ),
                ("assessed_at", models.DateTimeField(auto_now_add=True)),
                ("updated_at", models.DateTimeField(auto_now=True)),
                (
                    "assessed_by",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.CASCADE,
                        to=settings.AUTH_USER_MODEL,
                    ),
                ),
                (
                    "outcome",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="rob_assessments",
                        to="grade.outcome",
                    ),
                ),
                (
                    "study",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="rob_assessments",
                        to="grade.study",
                    ),
                ),
            ],
            options={
                "ordering": ["study__year", "study__title"],
                "unique_together": {("study", "outcome", "tool_used")},
            },
        ),
    ]
